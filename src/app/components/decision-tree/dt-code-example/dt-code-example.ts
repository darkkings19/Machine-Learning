import { Component } from '@angular/core';
import { CommonModule } from '@angular/common';
import { PythonRunnerComponent } from '../../python-runner/python-runner.component';

@Component({
  selector: 'app-dt-code-example',
  standalone: true,
  imports: [CommonModule, PythonRunnerComponent],
  templateUrl: './dt-code-example.html',
  styleUrl: './dt-code-example.css'
})
export class DtCodeExampleComponent {
  
  decisionTreeCode = `# Ãrboles de DecisiÃ³n - ClasificaciÃ³n de Flores Iris
# Este ejemplo muestra cÃ³mo usar Ã¡rboles de decisiÃ³n para clasificar flores

import numpy as np
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

print("ğŸŒ¸ Ejemplo de Ãrboles de DecisiÃ³n - Dataset Iris")
print("=" * 50)

# 1. Cargar el dataset Iris
print("ğŸ“Š Cargando dataset de flores Iris...")
iris = load_iris()
X = iris.data  # CaracterÃ­sticas: largo/ancho sÃ©palo y pÃ©talo
y = iris.target  # Clases: 0=Setosa, 1=Versicolor, 2=Virginica

print(f"Dataset cargado: {X.shape[0]} flores con {X.shape[1]} caracterÃ­sticas")
print(f"CaracterÃ­sticas: {iris.feature_names}")
print(f"Clases: {iris.target_names}")

# 2. Mostrar algunas muestras
print("\\nğŸ” Primeras 5 flores del dataset:")
for i in range(5):
    print(f"Flor {i+1}: {X[i]} -> {iris.target_names[y[i]]}")

# 3. Dividir datos en entrenamiento y prueba
print("\\nğŸ“ˆ Dividiendo datos en entrenamiento (80%) y prueba (20%)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"Datos de entrenamiento: {X_train.shape[0]} flores")
print(f"Datos de prueba: {X_test.shape[0]} flores")

# 4. Crear y entrenar el Ã¡rbol de decisiÃ³n
print("\\nğŸŒ³ Creando y entrenando el Ãrbol de DecisiÃ³n...")
clf = DecisionTreeClassifier(
    max_depth=3,  # Profundidad mÃ¡xima del Ã¡rbol
    random_state=42,
    criterion='gini'  # Criterio para medir la calidad de las divisiones
)

# Entrenar el modelo
clf.fit(X_train, y_train)
print("âœ… Ãrbol entrenado exitosamente!")

# 5. Hacer predicciones
print("\\nğŸ¯ Haciendo predicciones en datos de prueba...")
y_pred = clf.predict(X_test)

# 6. Evaluar el modelo
accuracy = accuracy_score(y_test, y_pred)
print(f"\\nğŸ“Š PrecisiÃ³n del modelo: {accuracy:.2%}")

# Mostrar predicciones vs realidad
print("\\nğŸ” ComparaciÃ³n de predicciones:")
print("Real -> PredicciÃ³n")
for i in range(min(10, len(y_test))):
    real = iris.target_names[y_test[i]]
    pred = iris.target_names[y_pred[i]]
    status = "âœ…" if y_test[i] == y_pred[i] else "âŒ"
    print(f"{real:12} -> {pred:12} {status}")

# 7. Importancia de las caracterÃ­sticas
print("\\nğŸ“ˆ Importancia de las caracterÃ­sticas:")
feature_importance = clf.feature_importances_
for i, importance in enumerate(feature_importance):
    print(f"{iris.feature_names[i]:20}: {importance:.3f}")

# 8. Predecir una nueva flor
print("\\nğŸŒº Prediciendo una nueva flor con caracterÃ­sticas:")
new_flower = [[5.1, 3.5, 1.4, 0.2]]  # CaracterÃ­sticas de una nueva flor
print(f"Largo sÃ©palo: {new_flower[0][0]} cm")
print(f"Ancho sÃ©palo: {new_flower[0][1]} cm") 
print(f"Largo pÃ©talo: {new_flower[0][2]} cm")
print(f"Ancho pÃ©talo: {new_flower[0][3]} cm")

prediction = clf.predict(new_flower)
probability = clf.predict_proba(new_flower)

print(f"\\nğŸ¯ PredicciÃ³n: {iris.target_names[prediction[0]]}")
print("ğŸ”¢ Probabilidades:")
for i, prob in enumerate(probability[0]):
    print(f"  {iris.target_names[i]:12}: {prob:.2%}")

print("\\nğŸ§  Â¿CÃ³mo funciona el Ã¡rbol de decisiÃ³n?")
print("El Ã¡rbol hace preguntas sobre las caracterÃ­sticas de la flor:")
print("- Â¿El ancho del pÃ©talo es <= 0.8? -> Si: Setosa")
print("- Â¿El ancho del pÃ©talo es <= 1.75? -> Si: Versicolor, No: Virginica")
print("Y asÃ­ sucesivamente hasta clasificar la flor.")

print("\\nâœ¨ Â¡ClasificaciÃ³n completada con Ãrboles de DecisiÃ³n!")`;

}

import { Component, OnInit, AfterViewInit, ElementRef, ViewChild, OnDestroy, Inject, PLATFORM_ID } from '@angular/core';
import { CommonModule, isPlatformBrowser } from '@angular/common';
import { FormsModule } from '@angular/forms';
import { PyodideService } from '../../services/pyodide.service';
import { MonacoEditorService } from '../../services/monaco-editor.service';
import * as monaco from 'monaco-editor';

@Component({
  selector: 'app-ejemplo-arbol',
  standalone: true,
  imports: [CommonModule, FormsModule],
  templateUrl: './ejemplo.component.html',
  styleUrl: './ejemplo.component.css'
})
export class EjemploArbolComponent implements OnInit, AfterViewInit, OnDestroy {
  
  @ViewChild('editorContainer', { static: true }) editorContainer!: ElementRef<HTMLDivElement>;
  
  // Estado del playground
  isReady = false;
  isLoading = true;
  isExecuting = false;
  statusText = 'Inicializando...';
  selectedExample: keyof typeof this.exampleInfo = 'basic';
  
  // Informaci√≥n de ejemplos
  exampleInfo = {
    basic: {
      title: 'üå≥ √Årbol B√°sico',
      description: 'Introducci√≥n a √°rboles de decisi√≥n con clasificaci√≥n del dataset Iris'
    },
    advanced: {
      title: 'üìä An√°lisis Avanzado', 
      description: 'An√°lisis detallado con matriz de confusi√≥n e importancia de caracter√≠sticas'
    },
    comparison: {
      title: '‚öñÔ∏è Comparaci√≥n de Algoritmos',
      description: 'Comparar rendimiento de √°rboles con otros algoritmos de ML'
    },
    visualization: {
      title: 'üìà Visualizaci√≥n de Reglas',
      description: 'Entender las reglas de decisi√≥n paso a paso'
    },
    interactive: {
      title: 'üéÆ Clasificador Interactivo',
      description: 'Experimenta con diferentes ejemplos de clasificaci√≥n'
    }
  } as const;
  
  // Resultados
  hasResults = false;
  hasError = false;
  executionOutput = '';
  executionError = '';
  
  // Editor
  private editor: monaco.editor.IStandaloneCodeEditor | null = null;
  
  // Ejemplos de c√≥digo
  private examples = {
    basic: `# √Årbol de Decisi√≥n B√°sico con Dataset Iris
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Cargar el dataset Iris
iris = load_iris()
X = iris.data  # caracter√≠sticas: largo/ancho del s√©palo y p√©talo
y = iris.target  # clases: 0=setosa, 1=versicolor, 2=virginica

print("üå∏ Dataset Iris cargado:")
print(f"N√∫mero de muestras: {len(X)}")
print(f"N√∫mero de caracter√≠sticas: {len(X[0])}")
print(f"Clases: {iris.target_names}")

# Dividir en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Crear y entrenar el √°rbol de decisi√≥n
tree = DecisionTreeClassifier(
    criterion='gini',
    max_depth=3,
    random_state=42
)
tree.fit(X_train, y_train)

# Hacer predicciones
y_pred = tree.predict(X_test)

# Evaluar el modelo
accuracy = accuracy_score(y_test, y_pred)
print(f"\\nüìä Precisi√≥n del modelo: {accuracy:.2f}")
print(f"üå≥ Profundidad del √°rbol: {tree.get_depth()}")
print(f"üî¢ N√∫mero de nodos: {tree.tree_.node_count}")

# Ejemplo de predicci√≥n con nueva flor
nueva_flor = [[5.1, 3.5, 1.4, 0.2]]  # caracter√≠sticas de una flor
prediccion = tree.predict(nueva_flor)
probabilidad = tree.predict_proba(nueva_flor)[0]

print(f"\\nüîÆ Predicci√≥n para nueva flor:")
print(f"Clase predicha: {iris.target_names[prediccion[0]]}")
print(f"Probabilidades:")
for i, prob in enumerate(probabilidad):
    print(f"  {iris.target_names[i]}: {prob:.3f}")`,

    advanced: `# An√°lisis Avanzado del √Årbol de Decisi√≥n
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Cargar datos
iris = load_iris()
X, y = iris.data, iris.target

print("üîç An√°lisis Avanzado de √Årboles de Decisi√≥n")
print("=" * 50)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Crear √°rbol con diferentes par√°metros
tree = DecisionTreeClassifier(
    criterion='gini',
    max_depth=4,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42
)

# Entrenar
tree.fit(X_train, y_train)

# Predicciones
y_pred = tree.predict(X_test)

# An√°lisis de resultados
accuracy = accuracy_score(y_test, y_pred)
print(f"üìä Precisi√≥n: {accuracy:.3f}")

# Importancia de caracter√≠sticas
importances = tree.feature_importances_
feature_names = iris.feature_names

print("\\nüéØ Importancia de caracter√≠sticas:")
for name, importance in zip(feature_names, importances):
    print(f"  {name}: {importance:.3f}")

# Matriz de confusi√≥n
cm = confusion_matrix(y_test, y_pred)
print("\\nüìã Matriz de confusi√≥n:")
print(cm)

# Estad√≠sticas del √°rbol
print(f"\\nüå≥ Estad√≠sticas del √°rbol:")
print(f"  Profundidad: {tree.get_depth()}")
print(f"  N√∫mero de nodos: {tree.tree_.node_count}")
print(f"  N√∫mero de hojas: {tree.get_n_leaves()}")

# An√°lisis de reglas simplificadas
print("\\nüìù Reglas del √°rbol (simplificadas):")
print("  Si petal length <= 2.5 -> Setosa")
print("  Si petal length > 2.5 y petal width <= 1.65 -> Versicolor")
print("  Si petal length > 2.5 y petal width > 1.65 -> Virginica")

# Reporte de clasificaci√≥n
print("\\nüìà Reporte de clasificaci√≥n:")
print(classification_report(y_test, y_pred, target_names=iris.target_names))`,

    comparison: `# Comparaci√≥n de Algoritmos de Clasificaci√≥n
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np

# Cargar datos
iris = load_iris()
X, y = iris.data, iris.target

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Definir modelos
models = {
    'üå≥ √Årbol de Decisi√≥n': DecisionTreeClassifier(random_state=42),
    'üå≤ Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'üî¢ KNN': KNeighborsClassifier(n_neighbors=3),
    'üéØ SVM': SVC(random_state=42),
    'üìä Naive Bayes': GaussianNB()
}

print("‚öñÔ∏è Comparaci√≥n de algoritmos de clasificaci√≥n")
print("=" * 60)

results = {}
for name, model in models.items():
    # Entrenamiento
    model.fit(X_train, y_train)
    
    # Predicciones
    y_pred = model.predict(X_test)
    
    # Evaluaci√≥n
    accuracy = accuracy_score(y_test, y_pred)
    
    # Validaci√≥n cruzada
    cv_scores = cross_val_score(model, X, y, cv=5)
    cv_mean = cv_scores.mean()
    cv_std = cv_scores.std()
    
    results[name] = {
        'accuracy': accuracy,
        'cv_mean': cv_mean,
        'cv_std': cv_std
    }
    
    print(f"\\n{name}:")
    print(f"  üìä Precisi√≥n en test: {accuracy:.3f}")
    print(f"  üîÑ Validaci√≥n cruzada: {cv_mean:.3f} ¬± {cv_std:.3f}")

# Resumen
print("\\n" + "=" * 60)
print("üèÜ RESUMEN:")
best_model = max(results.items(), key=lambda x: x[1]['cv_mean'])
print(f"ü•á Mejor modelo: {best_model[0]}")
print(f"üìà Precisi√≥n: {best_model[1]['cv_mean']:.3f}")

# Ventajas espec√≠ficas del √°rbol de decisi√≥n
print("\\nüå≥ Ventajas del √Årbol de Decisi√≥n:")
print("‚Ä¢ üìñ F√°cil interpretaci√≥n y visualizaci√≥n")
print("‚Ä¢ üî¢ No requiere escalado de caracter√≠sticas")
print("‚Ä¢ üìä Maneja variables categ√≥ricas naturalmente")
print("‚Ä¢ üåä Puede capturar relaciones no lineales")
print("‚Ä¢ ‚ö° Selecci√≥n autom√°tica de caracter√≠sticas")
print("‚Ä¢ üéØ R√°pido entrenamiento y predicci√≥n")`,

    visualization: `# Visualizaci√≥n y An√°lisis del √Årbol de Decisi√≥n
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import numpy as np

# Cargar y preparar datos
iris = load_iris()
X, y = iris.data, iris.target

print("üìä Visualizaci√≥n y An√°lisis del √Årbol de Decisi√≥n")
print("=" * 55)

# Usar solo 2 caracter√≠sticas para visualizaci√≥n
X_simple = X[:, [2, 3]]  # petal length y petal width
feature_names = ['Petal Length', 'Petal Width']

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X_simple, y, test_size=0.3, random_state=42
)

# Crear √°rbol simple
tree = DecisionTreeClassifier(
    criterion='gini',
    max_depth=3,
    random_state=42
)
tree.fit(X_train, y_train)

# Predicciones
y_pred = tree.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"üéØ Precisi√≥n con 2 caracter√≠sticas: {accuracy:.3f}")
print(f"üå≥ Profundidad del √°rbol: {tree.get_depth()}")

# Mostrar las reglas de decisi√≥n
print("\\nüìù Reglas de decisi√≥n extra√≠das:")
print("(Basadas en Petal Length y Petal Width)")
print()

# Simular decisiones paso a paso
test_samples = [
    [1.0, 0.2],  # Setosa
    [4.0, 1.3],  # Versicolor
    [6.0, 2.0],  # Virginica
]

for i, sample in enumerate(test_samples):
    prediction = tree.predict([sample])[0]
    proba = tree.predict_proba([sample])[0]
    
    print(f"üîç Muestra {i+1}: Petal Length={sample[0]}, Petal Width={sample[1]}")
    print(f"   Predicci√≥n: {iris.target_names[prediction]}")
    print(f"   Confianza: {proba[prediction]:.3f}")
    
    # Simular el recorrido del √°rbol
    if sample[0] <= 2.5:
        print("   üåø Regla: Petal Length <= 2.5 ‚Üí Setosa")
    elif sample[1] <= 1.65:
        print("   üåø Regla: Petal Length > 2.5 y Petal Width <= 1.65 ‚Üí Versicolor")
    else:
        print("   üåø Regla: Petal Length > 2.5 y Petal Width > 1.65 ‚Üí Virginica")
    print()

# Importancia de caracter√≠sticas
importances = tree.feature_importances_
print("üéØ Importancia de caracter√≠sticas:")
for name, importance in zip(feature_names, importances):
    print(f"  {name}: {importance:.3f}")

print("\\n‚ú® ¬°El √°rbol de decisi√≥n ha aprendido a clasificar flores!")
print("   Usa principalmente el largo del p√©talo como criterio principal.")`,

    interactive: `# √Årbol de Decisi√≥n Interactivo
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import numpy as np

print("üéÆ √Årbol de Decisi√≥n Interactivo")
print("=" * 40)

# Cargar datos
iris = load_iris()
X, y = iris.data, iris.target

# Entrenar modelo
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

tree = DecisionTreeClassifier(max_depth=3, random_state=42)
tree.fit(X_train, y_train)

print("üå∏ Clasificador de Iris entrenado!")
print("üìä Caracter√≠sticas: Sepal Length, Sepal Width, Petal Length, Petal Width")
print()

# Ejemplos de flores para clasificar
ejemplos = [
    [5.1, 3.5, 1.4, 0.2],  # Setosa t√≠pica
    [7.0, 3.2, 4.7, 1.4],  # Versicolor t√≠pica
    [6.3, 3.3, 6.0, 2.5],  # Virginica t√≠pica
    [5.5, 2.6, 4.0, 1.2],  # Ejemplo ambiguo
    [6.0, 3.0, 4.8, 1.8],  # Ejemplo l√≠mite
]

nombres_ejemplos = [
    "Setosa t√≠pica",
    "Versicolor t√≠pica", 
    "Virginica t√≠pica",
    "Caso ambiguo",
    "Caso l√≠mite"
]

for i, (ejemplo, nombre) in enumerate(zip(ejemplos, nombres_ejemplos)):
    print(f"üîç Ejemplo {i+1}: {nombre}")
    print(f"   Medidas: {ejemplo}")
    
    # Predicci√≥n
    prediccion = tree.predict([ejemplo])[0]
    probabilidades = tree.predict_proba([ejemplo])[0]
    
    print(f"   üéØ Predicci√≥n: {iris.target_names[prediccion]}")
    print(f"   üìä Probabilidades:")
    for j, prob in enumerate(probabilidades):
        print(f"      {iris.target_names[j]}: {prob:.3f}")
    
    # Mostrar confianza
    confianza = probabilidades[prediccion]
    if confianza > 0.9:
        print(f"   ‚úÖ Confianza: MUY ALTA ({confianza:.3f})")
    elif confianza > 0.7:
        print(f"   ‚ö†Ô∏è  Confianza: ALTA ({confianza:.3f})")
    else:
        print(f"   ‚ùì Confianza: MODERADA ({confianza:.3f})")
    print()

# Estad√≠sticas del modelo
accuracy = accuracy_score(y_test, tree.predict(X_test))
print(f"üìà Precisi√≥n del modelo: {accuracy:.3f}")
print(f"üå≥ Profundidad del √°rbol: {tree.get_depth()}")
print(f"üçÉ N√∫mero de hojas: {tree.get_n_leaves()}")

print("\\nüí° ¬°Experimenta cambiando los valores de las caracter√≠sticas!")
print("   Modifica los n√∫meros en los ejemplos para ver c√≥mo cambian las predicciones.")`
  };

  constructor(
    @Inject(PLATFORM_ID) private platformId: Object,
    private pyodideService: PyodideService,
    private monacoService: MonacoEditorService
  ) {}

  async ngOnInit() {
    if (!isPlatformBrowser(this.platformId)) {
      this.statusText = 'Solo disponible en el navegador';
      this.isLoading = false;
      return;
    }

    this.statusText = 'Cargando WebAssembly...';
    try {
      await this.pyodideService.init();
      this.statusText = 'Listo para ejecutar c√≥digo';
      this.isReady = true;
      this.isLoading = false;
    } catch (error) {
      this.statusText = 'Error al cargar WebAssembly';
      this.isLoading = false;
      console.error('Error inicializando Pyodide:', error);
    }
  }

  async ngAfterViewInit() {
    if (!isPlatformBrowser(this.platformId)) {
      return;
    }

    if (this.editorContainer) {
      try {
        this.editor = await this.monacoService.initEditor(
          this.editorContainer.nativeElement,
          this.examples.basic
        );
      } catch (error) {
        console.error('Error inicializando Monaco Editor:', error);
      }
    }
  }

  ngOnDestroy() {
    if (this.editor) {
      this.monacoService.dispose();
    }
  }

  async runCode() {
    if (!this.isReady || this.isExecuting) return;
    
    const code = this.monacoService.getValue();
    if (!code.trim()) {
      this.showError('No hay c√≥digo para ejecutar');
      return;
    }

    this.isExecuting = true;
    this.hasResults = false;
    this.hasError = false;
    this.executionOutput = '';
    this.executionError = '';

    try {
      const result = await this.pyodideService.runCode(code);
      
      if (result.error) {
        this.showError(result.error);
        this.executionOutput = result.output;
      } else {
        this.showSuccess(result.output);
      }
    } catch (error: any) {
      this.showError(error.message || 'Error desconocido');
    } finally {
      this.isExecuting = false;
    }
  }

  private showSuccess(output: string) {
    this.executionOutput = output || 'C√≥digo ejecutado exitosamente (sin salida)';
    this.hasResults = true;
    this.hasError = false;
  }

  private showError(error: string) {
    this.executionError = error;
    this.hasResults = true;
    this.hasError = true;
  }

  loadExample(type: string = 'basic') {
    if (!this.isReady) return;
    
    const exampleCode = this.examples[type as keyof typeof this.examples];
    if (exampleCode && type in this.exampleInfo) {
      this.selectedExample = type as keyof typeof this.exampleInfo;
      this.monacoService.setValue(exampleCode);
      this.clearResults();
    }
  }

  clearEditor() {
    if (!this.isReady) return;
    this.monacoService.setValue('');
    this.clearResults();
  }

  formatCode() {
    if (!this.isReady) return;
    this.monacoService.formatCode();
  }

  clearResults() {
    this.hasResults = false;
    this.hasError = false;
    this.executionOutput = '';
    this.executionError = '';
  }
}
